{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17856992-effa-46b7-bd0a-20fcf7ee7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41a26c1-9fd7-437a-ae1b-d3eee75c216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\programdata\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e4c7c-ed29-4777-a129-85cd8b4eaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = r\"D:\\Study Materials\\Project\\AnomaData_Capstone_Project\\data\\AnomaData.xlsx\"\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae46e68-8d0b-4d5c-a650-89b4394bc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information and first few rows\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179af40-c61c-4d67-8fb9-babcdddbdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Cleaning & Preprocessing\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d6156-49cd-4087-9b79-e9cb4b2a72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0539ed-a821-43da-94b3-36643f0df975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns with excessive missing values (threshold: 30% missing)\n",
    "threshold = 0.3 * len(df)\n",
    "df = df.dropna(thresh=threshold, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d99f0e-af4e-4e70-adb4-730955058c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining missing values with column median\n",
    "df = df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f0ba0-53a8-45a6-93c0-a185ed1f250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7835ade-f484-40a1-afde-440972d2059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate target column if it exists ('y.1' seems like a duplicate of 'y')\n",
    "if 'y.1' in df.columns:\n",
    "    df = df.drop(columns=['y.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143518b-88dc-447a-b536-ae31810999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset shape after preprocessing\n",
    "df.shape, missing_values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14919c-57e5-4126-8157-dc334f884c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b377f-1a8e-40bc-8458-1579c40ce26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2018de9-3817-482b-a6f6-2a61f785229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2efa30-dfd0-46f0-9ab5-cfffa683bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=df['y'], hue=df['y'], palette=\"viridis\", legend=False)  # Assign 'y' to hue\n",
    "plt.title(\"Distribution of Anomalies (Target Variable)\")\n",
    "plt.xlabel(\"Anomaly (1 = Yes, 0 = No)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0817e-13ad-4a11-8088-b582d5af93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (Top 10 correlated features with 'y')\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr_matrix = df.corr()\n",
    "top_corr_features = corr_matrix['y'].abs().sort_values(ascending=False).head(11).index\n",
    "sns.heatmap(df[top_corr_features].corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap (Top Features Related to Anomaly)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb74fe-d4a3-4d84-994b-865598424840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f069d-d786-42cd-b498-8383f2991984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e9df4-3de0-420b-8b22-05c94cb6432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895895c5-0ca9-4ebe-9968-4481418d21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Data\n",
    "X = df.drop(columns=['y', 'time'])  # Features (exclude target & timestamp)\n",
    "y = df['y']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39665905-7fc5-4c2c-87c0-e534b054a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5f076-21a1-4066-a571-541d2642d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train Isolation Forest Model\n",
    "model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75a8df-e217-421a-910a-8594a8bda5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Predict Anomalies\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b62399-5375-46c5-8c48-2e033a7f7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Isolation Forest output (-1 for anomaly, 1 for normal) to match target labels (1 for anomaly, 0 for normal)\n",
    "y_pred = [1 if pred == -1 else 0 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3befcac-52c2-4ca1-b10d-8f12f1327abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8cc282-e436-4f9f-9a2a-08f36227d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646ae7d-cb0d-4bbc-9015-ad007f2ae22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load trained model (For now, retrain within this script, but should load from a file)\n",
    "model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35490b9-6ee6-4136-a30e-12235178b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Load dataset\n",
    "    file_path = \"AnomaData.xlsx\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df.drop(columns=['y', 'time'])  # Drop target and timestamp\n",
    "    model.fit(df)\n",
    "    with open(\"model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e5eae-5dcf-4f6d-8ec4-ce52670f1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model if not already trained\n",
    "try:\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    train_model()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        features = np.array(data['features']).reshape(1, -1)  # Convert input to numpy array\n",
    "        prediction = model.predict(features)\n",
    "        result = \"Anomaly\" if prediction[0] == -1 else \"Normal\"\n",
    "        return jsonify({\"prediction\": result})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba99a69-0284-46ef-af39-6ee19054d639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f2802-33cb-476c-a1dc-bfd79fff90ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
